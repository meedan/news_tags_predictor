{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIKt2kIwk_p-"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sU5xnp6GlKEc"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/news_tagging_model\n",
    "# !mkdir news_tagging_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-y4061-ild8H"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bT4XqlcOllxh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"estadao_2010.csv\")\n",
    "df.category.value_counts()\n",
    "df_health = df[df['category'] == 'politica']\n",
    "df_health\n",
    "df_not_health = df[df['category'] != 'politica']\n",
    "df_not_health = df_not_health.sample(n=len(df_health),random_state=10)\n",
    "df_balanced = df_not_health.append(df_health)\n",
    "df_balanced.to_csv(\"balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKjd1tBWlkJ2"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmWdFc4Altde"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(outs):\n",
    "    predictions, labels = outs\n",
    "    predictions = np.argmax(predictions, axis = -1)\n",
    "\n",
    "    ## computes overall scores (accuracy, f1, recall, precision)\n",
    "    accuracy = accuracy_score(labels, predictions) * 100\n",
    "    f1 = f1_score(labels, predictions, average = \"macro\") * 100\n",
    "    recall = recall_score(labels, predictions, average = \"macro\") * 100\n",
    "    precision = precision_score(labels, predictions, average = \"macro\") * 100\n",
    "\n",
    "    return {\n",
    "        \"accuracy\" : float(accuracy),\n",
    "        \"f1\" : float(f1),\n",
    "        \"recall\" : float(recall),\n",
    "        \"precision\" : float(precision),\n",
    "    }\n",
    "\n",
    "def encode_labels(labels):\n",
    "  labels_set = set(labels)\n",
    "  endcoded_labels = labels\n",
    "  for j in range(len(endcoded_labels)):\n",
    "    if endcoded_labels[j] == 'politica':\n",
    "      endcoded_labels[j] = 1\n",
    "    else:\n",
    "      endcoded_labels[j] = 0\n",
    "  return endcoded_labels\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    read CSV file and return the tweets and labels lists\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    titles = df['title'].tolist()\n",
    "    labels = encode_labels(df['category'].tolist())\n",
    "    print(\"max(labels)\")\n",
    "\n",
    "    print(max(labels))\n",
    "    return titles, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7ICX7ccmFk5"
   },
   "outputs": [],
   "source": [
    "train_all_tweets, train_all_labels = load_data(\"/content/drive/MyDrive/news_tagging_model/balanced.csv\")\n",
    "test_tweets, test_labels = load_data(\"/content/drive/MyDrive/news_tagging_model/balanced.csv\")\n",
    "\n",
    "#split the train_all to train and validation\n",
    "train_tweets, val_tweets, train_labels, val_labels = train_test_split(\n",
    "    train_all_tweets,\n",
    "    train_all_labels,\n",
    "    test_size=.25,\n",
    "    random_state= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4D_a2dgmOSr"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "train_tweets_embeddings = model.encode(train_tweets, show_progress_bar = True )\n",
    "val_tweets_embeddings = model.encode(val_tweets, show_progress_bar = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BH8TZidP0WRt"
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import figure\n",
    "\n",
    "# pca = PCA()\n",
    "# Xt = pca.fit_transform(train_tweets_embeddings)\n",
    "\n",
    "# figure(figsize=(10, 10), dpi=80)\n",
    "# plot = plt.scatter(Xt[:,0], Xt[:,1], c=train_labels)\n",
    "# plt.legend(handles=plot.legend_elements()[0], labels=list(train_labels))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4umLq6ECmoQo"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QsBytWKgsTCp"
   },
   "outputs": [],
   "source": [
    "def make_embeddings_positive(embeddings):\n",
    "  min_emb = 100\n",
    "  for emb in embeddings:\n",
    "    current_min_emb = min(emb)\n",
    "    if current_min_emb < min_emb:\n",
    "      min_emb = current_min_emb\n",
    "  \n",
    "  min_emb = min_emb - 0.1 # just to not include 0\n",
    "  min_emb = min_emb * (-1)\n",
    "  for i in range(len(embeddings)):\n",
    "    for j in range(len(embeddings[i])):\n",
    "      embeddings[i][j]+=min_emb\n",
    "\n",
    "  return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44va9yxKspZU"
   },
   "outputs": [],
   "source": [
    "train_tweets_embeddings_fixed = make_embeddings_positive(train_tweets_embeddings)\n",
    "val_tweets_embeddings_fixed = make_embeddings_positive(val_tweets_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91a9GP7Yr59C"
   },
   "outputs": [],
   "source": [
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(train_tweets_embeddings_fixed, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IieAD7_8oreO"
   },
   "outputs": [],
   "source": [
    "y_pred = naive_bayes_classifier.predict(val_tweets_embeddings_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cm8z62FdszcZ"
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(val_labels, y_pred,\n",
    "                                            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hST1mhuFy_ta"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "train_tweets_embeddings = model.encode(train_tweets, show_progress_bar = True )\n",
    "val_tweets_embeddings = model.encode(val_tweets, show_progress_bar = True )\n",
    "\n",
    "train_tweets_embeddings_fixed = make_embeddings_positive(train_tweets_embeddings)\n",
    "val_tweets_embeddings_fixed = make_embeddings_positive(val_tweets_embeddings)\n",
    "\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(train_tweets_embeddings_fixed, train_labels)\n",
    "\n",
    "y_pred = naive_bayes_classifier.predict(val_tweets_embeddings_fixed)\n",
    "\n",
    "print(metrics.classification_report(val_labels, y_pred,\n",
    "                                            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYFzyhm015Ty"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
