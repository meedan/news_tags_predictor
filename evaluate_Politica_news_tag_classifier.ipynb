{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0t7_5kUA_eX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/news_tagging_model\n",
        "# !mkdir news_tagging_model"
      ],
      "metadata": {
        "id": "cPoRwATMBFon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "GSrBONl2BMRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "U02iRE0NBMfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # import pandas as pd\n",
        "# df = pd.read_csv(\"estadao_2010.csv\")\n",
        "# df.category.value_counts()\n",
        "# df_health = df[df['category'] == 'politica']\n",
        "# df_health\n",
        "# df_not_health = df[df['category'] != 'politica']\n",
        "# df_not_health = df_not_health.sample(n=len(df_health),random_state=10)\n",
        "# df_balanced = df_not_health.append(df_health)\n",
        "# df_balanced.to_csv(\"balanced.csv\")"
      ],
      "metadata": {
        "id": "rIg-ZC8dBOAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "# from omegaconf import DictConfig, OmegaConf\n",
        "# import hydra\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "# import wandb\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
      ],
      "metadata": {
        "id": "Lqe51aoeBQAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(outs):\n",
        "    predictions, labels = outs\n",
        "    predictions = np.argmax(predictions, axis = -1)\n",
        "\n",
        "    ## computes overall scores (accuracy, f1, recall, precision)\n",
        "    accuracy = accuracy_score(labels, predictions) * 100\n",
        "    f1 = f1_score(labels, predictions, average = \"macro\") * 100\n",
        "    recall = recall_score(labels, predictions, average = \"macro\") * 100\n",
        "    precision = precision_score(labels, predictions, average = \"macro\") * 100\n",
        "\n",
        "    return {\n",
        "        \"accuracy\" : float(accuracy),\n",
        "        \"f1\" : float(f1),\n",
        "        \"recall\" : float(recall),\n",
        "        \"precision\" : float(precision),\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "CXHF6sctBWRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_labels(labels):\n",
        "  labels_set = set(labels)\n",
        "  endcoded_labels = labels\n",
        "  # counter = 0\n",
        "  # for current_label in labels_set:\n",
        "  for j in range(len(endcoded_labels)):\n",
        "    # print(endcoded_labels[j] )\n",
        "    if endcoded_labels[j] == 'TRUE':\n",
        "      endcoded_labels[j] = 1\n",
        "    else:\n",
        "      endcoded_labels[j] = 0\n",
        "      # if endcoded_labels[j] == current_label:\n",
        "      #   endcoded_labels[j] = counter\n",
        "    # counter+=1\n",
        "  return endcoded_labels\n",
        "\n",
        "encode_labels([\"x\",\"health\",\"y\",\"x\",\"z\"])"
      ],
      "metadata": {
        "id": "UtkW8heMBZDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    \"\"\"\n",
        "    read CSV file and return the tweets and labels lists\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    titles = df['title'].tolist()\n",
        "    labels = encode_labels(df['Politics_Label'].tolist())\n",
        "    print(\"max(labels)\")\n",
        "\n",
        "    print(max(labels))\n",
        "    return titles, labels"
      ],
      "metadata": {
        "id": "gGxbYdiqBZVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiDialectDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels != None:\n",
        "          item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "9622YwuUBabH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Brazilian politics - estadao-export-2022-08-09.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "dFZYfJ58CiR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Politics_Label.value_counts()"
      ],
      "metadata": {
        "id": "N1rJ3X8bDaMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df =  df[df.Politics_Label.isin(['FALSE','TRUE'])]\n",
        "df"
      ],
      "metadata": {
        "id": "J1F9gpT9DhQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_tweets = df.title.tolist()\n",
        "val_labels = []\n",
        "for i in  df.Politics_Label.tolist():\n",
        "  if i == 'FALSE':\n",
        "    val_labels.append(0)\n",
        "  elif i == 'TRUE':\n",
        "    val_labels.append(1)\n",
        "# val_labels.replace('FALSE',0)"
      ],
      "metadata": {
        "id": "Kn8T5zzzDycK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Model...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/news_tagging_model/finetune_out/best_ckpt\", num_labels = 2)\n",
        "print(\"Loading Tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/news_tagging_model/finetune_out/best_ckpt\")\n"
      ],
      "metadata": {
        "id": "QAhUJc8fBbi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_all_tweets, train_all_labels = load_data(\"/content/drive/MyDrive/news_tagging_model/Brazilian politics - estadao-export-2022-08-09.csv\")\n",
        "# test_tweets, test_labels = load_data(\"/content/drive/MyDrive/news_tagging_model/Brazilian politics - estadao-export-2022-08-09.csv\")\n",
        "\n",
        "# #split the train_all to train and validation\n",
        "# train_tweets, val_tweets, train_labels, val_labels = train_test_split(\n",
        "#     train_all_tweets,\n",
        "#     train_all_labels,\n",
        "#     test_size=.99,\n",
        "#     random_state= 5)\n",
        "\n",
        "#tokenize the data\n",
        "print(\"Tokenizeing the inputs...\")\n",
        "# train_encodings = tokenizer(train_tweets,\n",
        "#                             truncation=True,\n",
        "#                             padding=True,\n",
        "#                             #max_length=model.config.max_position_embeddings\n",
        "#                             )\n",
        "val_encodings = tokenizer(val_tweets,\n",
        "                          truncation=True,\n",
        "                          padding=True,\n",
        "                            #max_length=model.config.max_position_embeddings\n",
        "                          )"
      ],
      "metadata": {
        "id": "Awv8NatdBh8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = MultiDialectDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "id": "ND--_y3oBjm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model)\n",
        "trainer.model = model.cuda()\n",
        "# y = trainer.predict(small_eval_dataset"
      ],
      "metadata": {
        "id": "wM0_DmuiBk9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_pred = trainer.predict(val_ds)\n"
      ],
      "metadata": {
        "id": "V0aJWJqnBmFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_0 = []\n",
        "pred_1 = []\n",
        "ispolitics_pred = []\n",
        "for pred in val_pred.predictions:\n",
        "  pred_0.append(pred[0])\n",
        "  pred_1.append(pred[1])\n",
        "  if pred[0]>pred[1]:\n",
        "    ispolitics_pred.append(0)\n",
        "  else:\n",
        "    ispolitics_pred.append(1)"
      ],
      "metadata": {
        "id": "FODeLTRSCGLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame({'title':val_tweets,'ispolitics_truth':val_labels,'ispolitics_pred':ispolitics_pred,'pred_0':pred_0,'pred_1':pred_1})"
      ],
      "metadata": {
        "id": "OQx6-N2TCKX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results.to_csv('Brazilian politics - estadao-export-2022-08-09 - prediction_output.csv')"
      ],
      "metadata": {
        "id": "bGNYTX3ACL3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(val_labels, ispolitics_pred)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "\n"
      ],
      "metadata": {
        "id": "3M9r188FCMTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "-btt3iJACNaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(val_labels, ispolitics_pred)\n",
        "\n"
      ],
      "metadata": {
        "id": "y5AzQIaC4rDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G9-mjtj94tsK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}