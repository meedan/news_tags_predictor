{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0t7_5kUA_eX"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPoRwATMBFon"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/news_tagging_model\n",
    "# !mkdir news_tagging_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ep8Btqw0YAzo"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSrBONl2BMRB"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lqe51aoeBQAP"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXHF6sctBWRc"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(outs):\n",
    "    predictions, labels = outs\n",
    "    predictions = np.argmax(predictions, axis = -1)\n",
    "\n",
    "    ## computes overall scores (accuracy, f1, recall, precision)\n",
    "    accuracy = accuracy_score(labels, predictions) * 100\n",
    "    f1 = f1_score(labels, predictions, average = \"macro\") * 100\n",
    "    recall = recall_score(labels, predictions, average = \"macro\") * 100\n",
    "    precision = precision_score(labels, predictions, average = \"macro\") * 100\n",
    "\n",
    "    return {\n",
    "        \"accuracy\" : float(accuracy),\n",
    "        \"f1\" : float(f1),\n",
    "        \"recall\" : float(recall),\n",
    "        \"precision\" : float(precision),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtkW8heMBZDu"
   },
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "  labels_set = set(labels)\n",
    "  endcoded_labels = labels\n",
    "\n",
    "  for j in range(len(endcoded_labels)):\n",
    "    if endcoded_labels[j] == 'politica':\n",
    "      endcoded_labels[j] = 1\n",
    "    else:\n",
    "      endcoded_labels[j] = 0\n",
    "  return endcoded_labels\n",
    "\n",
    "# encode_labels([\"x\",\"health\",\"y\",\"x\",\"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGxbYdiqBZVi"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    read CSV file and return the tweets and labels lists\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    titles = df['title'].tolist()\n",
    "    labels = encode_labels(df['category'].tolist())\n",
    "#     print(\"max(labels)\")\n",
    "\n",
    "#     print(max(labels))\n",
    "    return titles, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9622YwuUBabH"
   },
   "outputs": [],
   "source": [
    "class MultiDialectDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels != None:\n",
    "          item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffboro8i5SWu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "df = pd.read_csv(\"estadao_2010_2023.csv\")\n",
    "df = df[df['pubDate']>= str(2022)]\n",
    "df = df[df['pubDate']< str(2022+1)]\n",
    "df.category.value_counts()\n",
    "df_health = df[df['category'] == 'politica']\n",
    "df_health\n",
    "\n",
    "max_len = len(df_health)\n",
    "df_health = df_health.sample(n=max_len,random_state=10)\n",
    "df_not_health = df[df['category'] != 'politica']\n",
    "df_not_health = df_not_health.sample(n=max_len,random_state=10)\n",
    "df_balanced = df_not_health.append(df_health)\n",
    "df_balanced.to_csv(\"balanced_2022.csv\")\n",
    "\n",
    "print(\"------\")\n",
    "year_list = []\n",
    "f1_list = []\n",
    "for year in range(2006,2018):\n",
    "  year_list.append(year)\n",
    "  val_tweets, val_labels = load_data(\"/content/drive/MyDrive/news_tagging_model/balanced_2022.csv\")\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/news_tagging_model/microsoft_MiniLM-L12-H384-uncased_5epochs_\"+str(year)+\"-to-\"+str(year+1)+\"/best_ckpt\", num_labels = 2)\n",
    "  tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/news_tagging_model/microsoft_MiniLM-L12-H384-uncased_5epochs_2021/best_ckpt\")\n",
    "  val_encodings = tokenizer(val_tweets,\n",
    "                            truncation=True,\n",
    "                            padding=True,\n",
    "                              #max_length=model.config.max_position_embeddings\n",
    "                            )\n",
    "\n",
    "  val_ds = MultiDialectDataset(val_encodings, val_labels)\n",
    "  trainer = Trainer(model=model)\n",
    "  trainer.model = model.cuda()\n",
    "  val_pred = trainer.predict(val_ds)\n",
    "\n",
    "  pred_0 = []\n",
    "  pred_1 = []\n",
    "  ispolitics_pred = []\n",
    "  for pred in val_pred.predictions:\n",
    "    pred_0.append(pred[0])\n",
    "    pred_1.append(pred[1])\n",
    "    if pred[0]>pred[1]:\n",
    "      ispolitics_pred.append(0)\n",
    "    else:\n",
    "      ispolitics_pred.append(1)\n",
    "\n",
    "  df_results = pd.DataFrame({'title':val_tweets,'ispolitics_truth':val_labels,'ispolitics_pred':ispolitics_pred,'pred_0':pred_0,'pred_1':pred_1})\n",
    "  df_results.to_csv('Brazilian politics - estadao-export-2022-08-09 - prediction_output.csv')\n",
    "\n",
    "  cm = confusion_matrix(val_labels, ispolitics_pred)\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "  disp.plot()\n",
    " \n",
    "  f1 = f1_score(val_labels, ispolitics_pred)\n",
    "  print(\"f1 score for year = \"+str(year))\n",
    "  print(f1)\n",
    "  f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1F9gpT9DhQt"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"Brazilian politics - estadao-export-2022-08-09 - translated.csv\")\n",
    "# df =  df[df.Politics_Label.isin(['FALSE','TRUE'])]\n",
    "# val_tweets = df.title_es.tolist()\n",
    "# val_labels = []\n",
    "# for i in  df.Politics_Label.tolist():\n",
    "#   if i == 'FALSE':\n",
    "#     val_labels.append(0)\n",
    "#   elif i == 'TRUE':\n",
    "#     val_labels.append(1)\n",
    "# # val_labels.replace('FALSE',0)\n",
    "\n",
    "\n",
    "# year_list = []\n",
    "# f1_list = []\n",
    "# for year in range(2006,2018):\n",
    "#   # print(\"Loading Model...\")\n",
    "#   model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/news_tagging_model/microsoft_MiniLM-L12-H384-uncased_5epochs_\"+str(year)+\"-to-\"+str(year+1)+\"/best_ckpt\", num_labels = 2)\n",
    "#   # print(\"Loading Tokenizer...\")\n",
    "#   tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/news_tagging_model/microsoft_MiniLM-L12-H384-uncased_5epochs_2021/best_ckpt\")\n",
    "\n",
    "#   val_encodings = tokenizer(val_tweets,\n",
    "#                             truncation=True,\n",
    "#                             padding=True,\n",
    "#                               #max_length=model.config.max_position_embeddings\n",
    "#                             )\n",
    "\n",
    "#   val_ds = MultiDialectDataset(val_encodings, val_labels)\n",
    "#   trainer = Trainer(model=model)\n",
    "#   val_pred = trainer.predict(val_ds)\n",
    "\n",
    "#   pred_0 = []\n",
    "#   pred_1 = []\n",
    "#   ispolitics_pred = []\n",
    "#   for pred in val_pred.predictions:\n",
    "#     pred_0.append(pred[0])\n",
    "#     pred_1.append(pred[1])\n",
    "#     if pred[0]>pred[1]:\n",
    "#       ispolitics_pred.append(0)\n",
    "#     else:\n",
    "#       ispolitics_pred.append(1)\n",
    "\n",
    "#   df_results = pd.DataFrame({'title':val_tweets,'ispolitics_truth':val_labels,'ispolitics_pred':ispolitics_pred,'pred_0':pred_0,'pred_1':pred_1})\n",
    "\n",
    "#   cm = confusion_matrix(val_labels, ispolitics_pred)\n",
    "\n",
    "#   disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "#   disp.plot()\n",
    "\n",
    "#   f1 = f1_score(val_labels, ispolitics_pred)\n",
    "#   print(\"f1 score for year = \"+str(year))\n",
    "#   print(f1)\n",
    "#   f1_list.append(f1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
