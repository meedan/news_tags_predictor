{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0t7_5kUA_eX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPoRwATMBFon"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/news_tagging_model\n",
        "# !mkdir news_tagging_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "Ep8Btqw0YAzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSrBONl2BMRB"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U02iRE0NBMfg"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIg-ZC8dBOAU"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# df = pd.read_csv(\"univision_2015-2022_preprocessed.csv\")\n",
        "# df.category.value_counts()\n",
        "# df_health = df[df['is_politics'] == 1]\n",
        "# df_health\n",
        "# df_not_health = df[df['is_politics'] == 0]\n",
        "# df_not_health = df_not_health.sample(n=len(df_health),random_state=10)\n",
        "# df_balanced = df_not_health.append(df_health)\n",
        "# df_balanced.to_csv(\"balanced_univision.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g9lBLJfQgM4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqe51aoeBQAP"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "# from omegaconf import DictConfig, OmegaConf\n",
        "# import hydra\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "# import wandb\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXHF6sctBWRc"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(outs):\n",
        "    predictions, labels = outs\n",
        "    predictions = np.argmax(predictions, axis = -1)\n",
        "\n",
        "    ## computes overall scores (accuracy, f1, recall, precision)\n",
        "    accuracy = accuracy_score(labels, predictions) * 100\n",
        "    f1 = f1_score(labels, predictions, average = \"macro\") * 100\n",
        "    recall = recall_score(labels, predictions, average = \"macro\") * 100\n",
        "    precision = precision_score(labels, predictions, average = \"macro\") * 100\n",
        "\n",
        "    return {\n",
        "        \"accuracy\" : float(accuracy),\n",
        "        \"f1\" : float(f1),\n",
        "        \"recall\" : float(recall),\n",
        "        \"precision\" : float(precision),\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtkW8heMBZDu"
      },
      "outputs": [],
      "source": [
        "def encode_labels(labels):\n",
        "  labels_set = set(labels)\n",
        "  endcoded_labels = labels\n",
        "  # counter = 0\n",
        "  # for current_label in labels_set:\n",
        "  for j in range(len(endcoded_labels)):\n",
        "    # print(endcoded_labels[j] )\n",
        "    if endcoded_labels[j] == 'politica':\n",
        "      endcoded_labels[j] = 1\n",
        "    else:\n",
        "      endcoded_labels[j] = 0\n",
        "      # if endcoded_labels[j] == current_label:\n",
        "      #   endcoded_labels[j] = counter\n",
        "    # counter+=1\n",
        "  return endcoded_labels\n",
        "\n",
        "encode_labels([\"x\",\"health\",\"y\",\"x\",\"z\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGxbYdiqBZVi"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    \"\"\"\n",
        "    read CSV file and return the tweets and labels lists\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    titles = df['title'].tolist()\n",
        "    labels = encode_labels(df['category'].tolist())\n",
        "    print(\"max(labels)\")\n",
        "\n",
        "    print(max(labels))\n",
        "    return titles, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9622YwuUBabH"
      },
      "outputs": [],
      "source": [
        "class MultiDialectDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels != None:\n",
        "          item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "df = pd.read_csv(\"estadao_2010_2023.csv\")\n",
        "df = df[df['pubDate']>= str(2022)]\n",
        "df = df[df['pubDate']< str(2022+1)]\n",
        "df.category.value_counts()\n",
        "df_health = df[df['category'] == 'politica']\n",
        "df_health\n",
        "# print(len(df_health))\n",
        "max_len = len(df_health)\n",
        "# print(max_len)\n",
        "df_health = df_health.sample(n=max_len,random_state=10)\n",
        "# print(len(df_health))\n",
        "\n",
        "# print(len(df_not_health))\n",
        "df_not_health = df[df['category'] != 'politica']\n",
        "\n",
        "df_not_health = df_not_health.sample(n=max_len,random_state=10)\n",
        "# print(len(df_not_health))\n",
        "\n",
        "df_balanced = df_not_health.append(df_health)\n",
        "df_balanced.to_csv(\"balanced_2022.csv\")\n",
        "# print(len(df_health))\n",
        "\n",
        "# print(i)\n",
        "print(\"------\")\n",
        "year_list = []\n",
        "f1_list = []\n",
        "for year in range(2006,2018):\n",
        "\n",
        "\n",
        "  year_list.append(year)\n",
        "  # df = pd.read_csv(\"balanced_2022.csv\")\n",
        "  # df\n",
        "  val_tweets, val_labels = load_data(\"/content/drive/MyDrive/news_tagging_model/balanced_2022.csv\")\n",
        "\n",
        "\n",
        "  # print(\"Loading Model...\")\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/news_tagging_model/microsoft_MiniLM-L12-H384-uncased_5epochs_\"+str(year)+\"-to-\"+str(year+1)+\"/best_ckpt\", num_labels = 2)\n",
        "  # print(\"Loading Tokenizer...\")\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/news_tagging_model/microsoft_MiniLM-L12-H384-uncased_5epochs_2021/best_ckpt\")\n",
        "\n",
        "\n",
        "\n",
        "  # print(\"Tokenizeing the inputs...\")\n",
        "  # train_encodings = tokenizer(train_tweets,\n",
        "  #                             truncation=True,\n",
        "  #                             padding=True,\n",
        "  #                             #max_length=model.config.max_position_embeddings\n",
        "  #                             )\n",
        "  val_encodings = tokenizer(val_tweets,\n",
        "                            truncation=True,\n",
        "                            padding=True,\n",
        "                              #max_length=model.config.max_position_embeddings\n",
        "                            )\n",
        "\n",
        "\n",
        "  val_ds = MultiDialectDataset(val_encodings, val_labels)\n",
        "  trainer = Trainer(model=model)\n",
        "  trainer.model = model.cuda()\n",
        "  val_pred = trainer.predict(val_ds)\n",
        "\n",
        "\n",
        "  pred_0 = []\n",
        "  pred_1 = []\n",
        "  ispolitics_pred = []\n",
        "  for pred in val_pred.predictions:\n",
        "    pred_0.append(pred[0])\n",
        "    pred_1.append(pred[1])\n",
        "    if pred[0]>pred[1]:\n",
        "      ispolitics_pred.append(0)\n",
        "    else:\n",
        "      ispolitics_pred.append(1)\n",
        "\n",
        "\n",
        "  df_results = pd.DataFrame({'title':val_tweets,'ispolitics_truth':val_labels,'ispolitics_pred':ispolitics_pred,'pred_0':pred_0,'pred_1':pred_1})\n",
        "\n",
        "\n",
        "  df_results.to_csv('Brazilian politics - estadao-export-2022-08-09 - prediction_output.csv')\n",
        "\n",
        "\n",
        "  from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "  cm = confusion_matrix(val_labels, ispolitics_pred)\n",
        "\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "  disp.plot()\n",
        " \n",
        "  f1 = f1_score(val_labels, ispolitics_pred)\n",
        "  print(\"f1 score for year = \"+str(year))\n",
        "  print(f1)\n",
        "  f1_list.append(f1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ffboro8i5SWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(f1_list)):\n",
        "  print(str(year_list[i])+'-->'+str(f1_list[i]))"
      ],
      "metadata": {
        "id": "cCdiy-XX9yKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1rJ3X8bDaMK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1F9gpT9DhQt"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Brazilian politics - estadao-export-2022-08-09 - translated.csv\")\n",
        "df =  df[df.Politics_Label.isin(['FALSE','TRUE'])]\n",
        "val_tweets = df.title_es.tolist()\n",
        "val_labels = []\n",
        "for i in  df.Politics_Label.tolist():\n",
        "  if i == 'FALSE':\n",
        "    val_labels.append(0)\n",
        "  elif i == 'TRUE':\n",
        "    val_labels.append(1)\n",
        "# val_labels.replace('FALSE',0)\n",
        "\n",
        "\n",
        "year_list = []\n",
        "f1_list = []\n",
        "for year in range(2006,2018):\n",
        "  # print(\"Loading Model...\")\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/news_tagging_model/microsoft_MiniLM-L12-H384-uncased_5epochs_\"+str(year)+\"-to-\"+str(year+1)+\"/best_ckpt\", num_labels = 2)\n",
        "  # print(\"Loading Tokenizer...\")\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/news_tagging_model/microsoft_MiniLM-L12-H384-uncased_5epochs_2021/best_ckpt\")\n",
        "\n",
        "  val_encodings = tokenizer(val_tweets,\n",
        "                            truncation=True,\n",
        "                            padding=True,\n",
        "                              #max_length=model.config.max_position_embeddings\n",
        "                            )\n",
        "\n",
        "  val_ds = MultiDialectDataset(val_encodings, val_labels)\n",
        "  trainer = Trainer(model=model)\n",
        "  val_pred = trainer.predict(val_ds)\n",
        "\n",
        "  pred_0 = []\n",
        "  pred_1 = []\n",
        "  ispolitics_pred = []\n",
        "  for pred in val_pred.predictions:\n",
        "    pred_0.append(pred[0])\n",
        "    pred_1.append(pred[1])\n",
        "    if pred[0]>pred[1]:\n",
        "      ispolitics_pred.append(0)\n",
        "    else:\n",
        "      ispolitics_pred.append(1)\n",
        "\n",
        "  df_results = pd.DataFrame({'title':val_tweets,'ispolitics_truth':val_labels,'ispolitics_pred':ispolitics_pred,'pred_0':pred_0,'pred_1':pred_1})\n",
        "\n",
        "  cm = confusion_matrix(val_labels, ispolitics_pred)\n",
        "\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "  disp.plot()\n",
        "\n",
        "  f1 = f1_score(val_labels, ispolitics_pred)\n",
        "  print(\"f1 score for year = \"+str(year))\n",
        "  print(f1)\n",
        "  f1_list.append(f1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(f1_list)):\n",
        "  print(str(f1_list[len(f1_list)-i-1]))\n",
        "  # print(str(year_list[i])+'-->'+str(f1_list[i]))"
      ],
      "metadata": {
        "id": "iTdZiarGBnU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn8T5zzzDycK"
      },
      "outputs": [],
      "source": [
        "# val_tweets = df.title.tolist()\n",
        "# val_labels = df.is_politics.tolist()\n",
        "# # for i in  df.Politics_Label.tolist():\n",
        "# #   if i == 'FALSE':\n",
        "# #     val_labels.append(0)\n",
        "# #   elif i == 'TRUE':\n",
        "# #     val_labels.append(1)\n",
        "# # # val_labels.replace('FALSE',0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bq7VjqjlBmuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAhUJc8fBbi2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Awv8NatdBh8Y"
      },
      "outputs": [],
      "source": [
        "# train_all_tweets, train_all_labels = load_data(\"/content/drive/MyDrive/news_tagging_model/Brazilian politics - estadao-export-2022-08-09.csv\")\n",
        "# test_tweets, test_labels = load_data(\"/content/drive/MyDrive/news_tagging_model/Brazilian politics - estadao-export-2022-08-09.csv\")\n",
        "\n",
        "# #split the train_all to train and validation\n",
        "# train_tweets, val_tweets, train_labels, val_labels = train_test_split(\n",
        "#     train_all_tweets,\n",
        "#     train_all_labels,\n",
        "#     test_size=.99,\n",
        "#     random_state= 5)\n",
        "\n",
        "#tokenize the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND--_y3oBjm4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM0_DmuiBk9z"
      },
      "outputs": [],
      "source": [
        "# trainer.model = model.cuda()\n",
        "# y = trainer.predict(small_eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0aJWJqnBmFK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FODeLTRSCGLi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQx6-N2TCKX5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGNYTX3ACL3d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M9r188FCMTZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-btt3iJACNaG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5AzQIaC4rDK"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9-mjtj94tsK"
      },
      "outputs": [],
      "source": [
        "2018 -> 0.8413999479573251 - 0.7377049180327869\n",
        "2019 -> 0.8595555555555555 - 0.7301587301587301\n",
        "2020 -> 0.8690936292232889 - 0.7000000000000001\n",
        "2021 -> 0.8715429114826848 - 0.6861313868613138"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q9j2bSmxjkAH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}